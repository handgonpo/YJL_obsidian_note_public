프로젝트 코드명: `PatternInsight`
프로젝트 유형: 텍스트 기반 **패턴 분석 도구** (콘솔 기반)

### 🖥️ 프로젝트 개요
```python
사용자 피드백 데이터에서 반복적으로 등장하는 문장 구조 패턴을 분석하여,
- 패턴별 출현 횟수   
- 사용자별 피드백 길이 편차
- 패턴과 긍정/부정 여부의 상관관계등을 분석하는 텍스트 인사이트 도구를 
  개발합니다.
```

##### ◽ **이 프로젝트를 통해 자연스럽게 적용되는 내용**
| 개념           | 적용 내용                                           |
| ------------ | ----------------------------------------------- |
| `이터레이터`      | 사용자별 피드백 순차 접근 및 next 조작                        |
| `리스트 컴프리헨션`  | 텍스트 패턴 정제 및 분류                                  |
| `딕셔너리 컴프리헨션` | 사용자-문장 길이 매핑, 패턴 분류                             |
| `내장 함수`      | `enumerate`, `reversed`, `max`, `min`, `sum` 등  |
| `문자열 메서드`    | 패턴 분리 (`split`, `startswith`, `count`, `strip`) |
| `조건문/반복문`    | 텍스트 평가 및 분기처리                                   |
| `집계 통계 사고`   | 평균 길이 편차, 상관관계 추정 로직                            |

---

### 📄 기능 요구사항 (Functional Requirements)
1. 다중 사용자 피드백 데이터를 처리합니다.  
    각 사용자는 여러 개의 피드백을 가지고 있으며, 피드백은 리스트에 중첩 구조로 저장됩니다.
2. 피드백에서 문장 구조 패턴을 추출합니다.
    - 예: `"서비스가 좋다"`, `"배송이 느리다"` 등 (단어 수 기준 3단어 이하)
3. 패턴별 출현 횟수를 딕셔너리로 집계합니다.
4. 각 사용자별로 평균 문장 길이를 구하고, 전체 사용자 중 최대 편차 사용자를 출력합니다.
5. 특정 키워드(`good`, `bad`)가 포함된 피드백이 어떤 패턴에 집중되는지 분석합니다.
6. 이터레이터와 `next()`를 활용해 사용자 데이터를 순차 처리하면서 에러 없이 3개까지만 피드백을 분석합니다.

---
### 📄 비기능 요구사항 (Non-Functional)
- 컴프리헨션 필수 사용
- 이터레이터 + next()를 활용하여 일부 데이터만 추출
- 분석 결과는 구조화된 콘솔 포맷으로 출력
- 2시간 내 구현이 가능하도록 전체 데이터는 코드 내 고정

---
### ✅ 출력 포맷 예시

```python
📊 Pattern Insight Report
-------------------------------------
1. 총 사용자 수: 4명
2. 총 수집된 피드백 수: 12개
3. 상위 3개 피드백 패턴:
   - "service is slow": 3회
   - "delivery was late": 2회
   - "good product": 2회
4. 사용자별 평균 피드백 길이:
   - user1: 6.3단어
   - user2: 3.0단어
   - user3: 8.0단어
   - user4: 2.0단어
   → 최대 편차 사용자: user3
5. 긍정 키워드가 포함된 패턴 분포:
   - "good product": 2회
   - "fast shipping": 1회
6. 다음 사용자 3명의 피드백 미리보기 (이터레이터 기반):
   - user1: ["Service is slow", "Delivery was late", "Support was bad"]
   - user2: ["Good product"]
   - user3: ["I love it"]
```

✅ 정답 코드:
```python
feedback_data = {
    "user1": ["Service is slow", "Delivery was late", "Support was bad"],
    "user2": ["Good product", "Fast shipping"],
    "user3": ["I love it", "Great service and response", "Product quality is amazing"],
    "user4": ["Bad", "Late"]
}

# 1. 패턴 추출 함수 (3단어 이하 추출)
def extract_patterns(feedback):
    return [" ".join(w.strip(".,!?").lower() for w in f.split()[:3]) for f in feedback]

# 2. 패턴 집계
all_patterns = [p for user in feedback_data.values() for p in extract_patterns(user)]
pattern_count = {p: all_patterns.count(p) for p in set(all_patterns)}

# 3. 사용자별 평균 피드백 길이
user_lengths = {user: sum(len(f.split()) for f in fbs)/len(fbs) for user, fbs in feedback_data.items()}
max_user = max(user_lengths.items(), key=lambda x: x[1])[0]

# 4. 긍정 키워드 포함 패턴
positive_patterns = [p for fbs in feedback_data.values() for f in fbs if "good" in f.lower() or "fast" in f.lower() for p in extract_patterns([f])]
positive_summary = {p: positive_patterns.count(p) for p in set(positive_patterns)}

# 5. 이터레이터로 3명만 출력
user_iter = iter(feedback_data.items())
preview = [next(user_iter) for _ in range(3)]

# 6. 결과 출력
print("📊 Pattern Insight Report\n" + "-"*40)
print(f"1. 총 사용자 수: {len(feedback_data)}명")
print(f"2. 총 수집된 피드백 수: {sum(len(f) for f in feedback_data.values())}개")
print("3. 상위 3개 피드백 패턴:")
for p, c in sorted(pattern_count.items(), key=lambda x: x[1], reverse=True)[:3]:
    print(f"   - \"{p}\": {c}회")
print("4. 사용자별 평균 피드백 길이:")
for u, l in user_lengths.items():
    print(f"   - {u}: {round(l, 1)}단어")
print(f"   → 최대 편차 사용자: {max_user}")
print("5. 긍정 키워드가 포함된 패턴 분포:")
for p, c in positive_summary.items():
    print(f"   - \"{p}\": {c}회")
print("6. 다음 사용자 3명의 피드백 미리보기 (이터레이터 기반):")
for u, fbs in preview:
    print(f"   - {u}: {fbs}")
```

| 항목     | 설명                         |
| ------ | -------------------------- |
| 난이도    | 고급 (상관관계 추정, 평균 편차 등 포함)   |
| 논리력 요구 | 텍스트 전처리, 조건 분기, 이터레이터 조작 등 |
| 실무 활용성 | 리뷰 분석, NLP 기초 데이터 처리       |
| 학습 요소  | 고차 함수, 자료구조 통합적 사고, 조건 분기  |

---
코드 일부 해설:

🔹 ① 텍스트 정제 및 소문자화
```python
" ".join(w.strip(".,!?").lower() for w in f.split()[:3])
```

- `strip(".,!?")` → 구두점 제거
- `.lower()` → 대소문자 통일
- `split()` → 문장을 단어 단위로 나누기 (간이 토큰화)

이것은 NLP의 텍스트 정제 + 토큰화 + 정규화(Normalization)에 해당합니다.

---
🔹 ② 패턴 추출 및 빈도 분석
```python
pattern_count = {p: all_patterns.count(p) for p in set(all_patterns)}
```

- 전체 문장에서 유사한 문장 구조(패턴)를 추출하고, 빈도수 집계를 합니다.
- NLP에서는 n-gram 분석이나 phrase mining이라고 불리는 기법의 단순 버전입니다.

---
🔹 ③ 감성 키워드 기반 분류
```python
if "good" in f.lower() or "fast" in f.lower():
```

- `"good"`, `"bad"` 등 감정 표현 단어를 기반으로 긍정/부정을 판단합니다.
- 이것은 감정 분석(Sentiment Analysis)의 초기 단계이며,  
    머신러닝 없이도 키워드 기반으로 처리하는 방식입니다.

---
🔹 ④ 사용자별 피드백 길이 분석
```python
sum(len(f.split()) for f in fbs)/len(fbs)
```

- 텍스트의 길이 분석은 NLP에서 문서 특성(텍스트 분포, 복잡도 등)을 파악할 때 활용됩니다.
- 예: SNS 감정 분석, 이메일 분류 등